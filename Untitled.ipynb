{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "#K.set_session(tf.Session(config=tf.ConfigProto(device_count={'gpu':0})))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "'''\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "set_session(tf.Session(config=config))\n",
    "'''\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dropout,Lambda, Dense, Conv2D,Flatten,AveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import Nadam\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUIQfCIrwA0H9H4BpmwJXvvG+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1725816d9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0][0],cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train /255\n",
    "X_test = X_test /255\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_class = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import get_custom_objects\n",
    "def custom_STF_activation(x,alpha=1.4):\n",
    "    ''' \n",
    "       Arguments:\n",
    "       x: input tensor\n",
    "       alpha: index\n",
    "       Returns:\n",
    "       Tensor, output of stf function\n",
    "    '''\n",
    "    x_ = tf.nn.relu(x)\n",
    "    y = x_**alpha\n",
    "    return (y)\n",
    "\n",
    "## how to define the log function\n",
    "def custom_STD_activation(x,beta=1.1):\n",
    "    x_ = tf.nn.relu(x)\n",
    "    denominator = tf.log(tf.constant(beta,dtype=x_.dtype))\n",
    "    y = x_/denominator\n",
    "    return (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32,5,5,border_mode='valid',input_shape=(1,28,28),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dense(num_class,activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seed = 13\n",
    "np.random.seed(seed)\n",
    "model = base_model()\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),nb_epoch=10,batch_size=200,verbose=2)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model2(lr=0.0005,decay=0.0):\n",
    "    input_layer =Input(shape=(1,28,28))\n",
    "    conv_layer1=Conv2D(6,5,padding='valid',activation='relu')(input_layer)\n",
    "    max_pool1 = MaxPooling2D(pool_size=(2,2),strides=2)(conv_layer1)\n",
    "    conv_layer2=Conv2D(16,5,padding='valid',activation=custom_STD_activation)(max_pool1)\n",
    "    max_pool2 = MaxPooling2D(pool_size=(2,2),strides=2)(conv_layer2)\n",
    "    main2 = Dropout(0.2)(max_pool2)\n",
    "    main2 = Flatten()(main2)\n",
    "    main2 = Dense(128,activation='relu')(main2)\n",
    "    main2 = Dense(84,activation='relu')(main2)\n",
    "    output = Dense(10,activation='softmax')(main2)\n",
    "    model = Model(input_layer,output)\n",
    "   # optimizer = RMSprop(lr=0.001,rho=0.9,epsilon=1e-08,decay=0.0)\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 1, 28, 28)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 6, 24, 24)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 6, 12, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 16, 8, 8)          2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 16, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 84)                10836     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 47,154\n",
      "Trainable params: 47,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = base_model2()\n",
    "model.summary()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " 3744/60000 [>.............................] - ETA: 46s - loss: 0.8420 - acc: 0.7249"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-780c2b094994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlr_decay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_decay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_fin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcnn_model2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_model2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcnn_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set hyper parameters for the model.\n",
    "BATCH_SIZE = 256\n",
    "epochs = 10\n",
    "# Calculate learning rate decay.\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(X_train) / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.005, 0.0003\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "cnn_model2 = base_model2()\n",
    "cnn_model2.fit(x=X_train,y=y_train,batch_size=16,epochs=20,verbose=1,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2af561c5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(cnn_model2.history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(cnn_model2.history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(cnn_model2.history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(cnn_model2.history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1, 28, 28)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 6, 24, 24)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 12, 12)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 8, 8)          2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10836     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 47,154\n",
      "Trainable params: 47,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def base_model2_adam(lr=0.0005,decay=0.0):\n",
    "    input_layer =Input(shape=(1,28,28))\n",
    "    conv_layer1=Conv2D(6,5,padding='valid',activation='relu')(input_layer)\n",
    "    max_pool1 = MaxPooling2D(pool_size=(2,2),strides=2)(conv_layer1)\n",
    "    conv_layer2=Conv2D(16,5,padding='valid',activation='relu')(max_pool1)\n",
    "    max_pool2 = MaxPooling2D(pool_size=(2,2),strides=2)(conv_layer2)\n",
    "    main2 = Dropout(0.2)(max_pool2)\n",
    "    main2 = Flatten()(main2)\n",
    "    main2 = Dense(128,activation='relu')(main2)\n",
    "    main2 = Dense(84,activation='relu')(main2)\n",
    "    output = Dense(10,activation='softmax')(main2)\n",
    "    model = Model(input_layer,output)\n",
    "    optimizer = Adam(lr=0.001,beta_1=0.9,beta_2=0.89,epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model\n",
    "model = base_model2_adam()\n",
    "model.summary()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 115s - loss: 0.2481 - acc: 0.9239 - val_loss: 0.0319 - val_acc: 0.9891\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 113s - loss: 0.0704 - acc: 0.9777 - val_loss: 0.0231 - val_acc: 0.9919\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 112s - loss: 0.0539 - acc: 0.9828 - val_loss: 0.0220 - val_acc: 0.9925\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 110s - loss: 0.0458 - acc: 0.9856 - val_loss: 0.0218 - val_acc: 0.9922\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 107s - loss: 0.0412 - acc: 0.9870 - val_loss: 0.0185 - val_acc: 0.9940\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 108s - loss: 0.0380 - acc: 0.9878 - val_loss: 0.0200 - val_acc: 0.9937\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 112s - loss: 0.0354 - acc: 0.9887 - val_loss: 0.0200 - val_acc: 0.9930\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 112s - loss: 0.0327 - acc: 0.9897 - val_loss: 0.0173 - val_acc: 0.9946\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 108s - loss: 0.0326 - acc: 0.9894 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 108s - loss: 0.0299 - acc: 0.9904 - val_loss: 0.0201 - val_acc: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16e30997908>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set hyper parameters for the model.\n",
    "datagen = ImageDataGenerator(zoom_range = 0.05,\n",
    "                            height_shift_range = 0.05,\n",
    "                            width_shift_range = 0.05,\n",
    "                            rotation_range = 3)\n",
    "BATCH_SIZE = 256\n",
    "epochs = 10\n",
    "# Calculate learning rate decay.\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(X_train) / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.005, 0.0003\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "cnn_model3 = base_model2_adam()\n",
    "cnn_model3.fit_generator(\n",
    "        datagen.flow(X_train, y_train, batch_size=256),steps_per_epoch=1000, epochs=epochs,\n",
    "        validation_data=(X_test, y_test), verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 1, 28, 28)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 24, 24)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 30, 23, 23)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 15, 21, 21)        4065      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 15, 20, 20)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 20, 20)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               768128    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 84)                10836     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 784,659\n",
      "Trainable params: 784,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def base_model3(lr=0.001,decay=0.0):\n",
    "    input_layer =Input(shape=(1,28,28))\n",
    "    conv_layer1=Conv2D(30,(5,5),padding='valid',activation='relu')(input_layer)\n",
    "    avg_pool1 = MaxPooling2D(pool_size=(2,2),strides=1)(conv_layer1)\n",
    "    conv_layer2=Conv2D(15,(3,3),padding='valid',activation='relu')(avg_pool1)\n",
    "    avg_pool2 = MaxPooling2D(pool_size=(2,2),strides=1)(conv_layer2)\n",
    "    main2 = Dropout(0.2)(avg_pool2)\n",
    "    main2 = Flatten()(main2)\n",
    "    main2 = Dense(128,activation='relu')(main2)\n",
    "    #main2 = Dropout(0.1)(Dense(128,activation='relu')(main2))\n",
    "    main2 = Dense(84,activation='relu')(main2)\n",
    "    output = Dense(10,activation='softmax')(main2)\n",
    "    model = Model(input_layer,output)\n",
    "    optimizer = Adam(lr=0.001,beta_1=0.9,beta_2=0.9,epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model\n",
    "model = base_model3()\n",
    "model.summary()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   3/1000 [..............................] - ETA: 10:52 - loss: 2.2312 - acc: 0.1445"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(zoom_range = 0.05,\n",
    "                            height_shift_range = 0.05,\n",
    "                            width_shift_range = 0.05,\n",
    "                            rotation_range = 3)\n",
    "BATCH_SIZE = 256\n",
    "epochs = 10\n",
    "# Calculate learning rate decay.\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(X_train) / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.007, 0.0003\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "cnn_model = base_model3(lr=lr_init,decay=0)\n",
    "cnn_model.fit_generator(\n",
    "        datagen.flow(X_train, y_train, batch_size=256),steps_per_epoch=1000, epochs=epochs,\n",
    "        validation_data=(X_test, y_test), verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = cnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def larger_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(30, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(15, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Larger CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 1, 28, 28)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 32, 28, 28)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 32, 28, 28)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 64, 14, 14)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 64, 14, 14)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 64, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 919,146\n",
      "Trainable params: 919,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def base_model4(lr=0.0005,decay=0.0):\n",
    "    input_layer =Input(shape=(1,28,28))\n",
    "    conv_layer1 = Conv2D(32,(5,5),padding = 'same',activation='relu')(input_layer)\n",
    "    conv_layer2 = Conv2D(32,(5,5),padding = 'same',activation='relu')(conv_layer1)\n",
    "    max_pool1 = MaxPooling2D(pool_size=(2,2))(conv_layer2)\n",
    "    main1 = Dropout(0.25)(max_pool1)\n",
    "    conv_layer3 = Conv2D(64,(3,3),padding='same',activation='relu')(main1)\n",
    "    conv_layer4 = Conv2D(64,(3,3),padding='same',activation='relu')(conv_layer3)\n",
    "    max_pool2 = MaxPooling2D(pool_size=(2,2),strides=2)(conv_layer4)\n",
    "    main2 = Dropout(0.2)(max_pool2)\n",
    "    main2 = Flatten()(main2)\n",
    "    main2 = Dense(256,activation='relu')(main2)\n",
    "    main2 = Dense(128,activation='relu')(main2)\n",
    "    output = Dense(10,activation='softmax')(main2)\n",
    "    model = Model(input_layer,output)\n",
    "    #optimizer = Adam(lr=lr,decay=decay)\n",
    "    optimizer = RMSprop(lr=0.001,rho=0.9,epsilon=1e-08,decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "model = base_model4()\n",
    "model.summary()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "330/330 [==============================] - 209s - loss: 0.3686 - acc: 0.8804 - val_loss: 0.0648 - val_acc: 0.9797\n",
      "Epoch 2/20\n",
      "330/330 [==============================] - 205s - loss: 0.1090 - acc: 0.9673 - val_loss: 0.0364 - val_acc: 0.9878\n",
      "Epoch 3/20\n",
      "330/330 [==============================] - 212s - loss: 0.0815 - acc: 0.9752 - val_loss: 0.0353 - val_acc: 0.9886\n",
      "Epoch 4/20\n",
      "330/330 [==============================] - 212s - loss: 0.0766 - acc: 0.9772 - val_loss: 0.0579 - val_acc: 0.9817\n",
      "Epoch 5/20\n",
      "330/330 [==============================] - 215s - loss: 0.0611 - acc: 0.9819 - val_loss: 0.0256 - val_acc: 0.9923\n",
      "Epoch 6/20\n",
      "330/330 [==============================] - 211s - loss: 0.0554 - acc: 0.9838 - val_loss: 0.0366 - val_acc: 0.9894\n",
      "Epoch 7/20\n",
      "330/330 [==============================] - 205s - loss: 0.0501 - acc: 0.9858 - val_loss: 0.0199 - val_acc: 0.9927\n",
      "Epoch 8/20\n",
      "330/330 [==============================] - 206s - loss: 0.0556 - acc: 0.9840 - val_loss: 0.0225 - val_acc: 0.9929\n",
      "Epoch 9/20\n",
      "330/330 [==============================] - 206s - loss: 0.0498 - acc: 0.9857 - val_loss: 0.0213 - val_acc: 0.9933\n",
      "Epoch 10/20\n",
      "330/330 [==============================] - 203s - loss: 0.0513 - acc: 0.9852 - val_loss: 0.0213 - val_acc: 0.9932\n",
      "Epoch 11/20\n",
      "330/330 [==============================] - 201s - loss: 0.0506 - acc: 0.9854 - val_loss: 0.0222 - val_acc: 0.9933\n",
      "Epoch 12/20\n",
      "330/330 [==============================] - 200s - loss: 0.0453 - acc: 0.9864 - val_loss: 0.0246 - val_acc: 0.9922\n",
      "Epoch 13/20\n",
      "330/330 [==============================] - 202s - loss: 0.0448 - acc: 0.9867 - val_loss: 0.0267 - val_acc: 0.9915\n",
      "Epoch 14/20\n",
      "330/330 [==============================] - 202s - loss: 0.0475 - acc: 0.9866 - val_loss: 0.0187 - val_acc: 0.9946\n",
      "Epoch 15/20\n",
      "  9/330 [..............................] - ETA: 163s - loss: 0.0574 - acc: 0.9841"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-68a02703a44e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m cnn_model.fit_generator(\n\u001b[0;32m     14\u001b[0m         \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m330\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m )\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2042\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2044\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1762\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1763\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1764\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\study\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(zoom_range = 0.05,\n",
    "                            height_shift_range = 0.05,\n",
    "                            width_shift_range = 0.05,\n",
    "                            rotation_range = 3)\n",
    "BATCH_SIZE = 200\n",
    "epochs = 20\n",
    "# Calculate learning rate decay.\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(X_train) / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.002, 0.0003\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "cnn_model = base_model4(lr=lr_init,decay=0)\n",
    "cnn_model.fit_generator(\n",
    "        datagen.flow(X_train, y_train, batch_size=256),steps_per_epoch=1000, epochs=epochs,\n",
    "        validation_data=(X_test, y_test), verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 1, 28, 28)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 32, 28, 28)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 32, 28, 28)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 32, 14, 14)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 64, 14, 14)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 64, 14, 14)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 64, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64, 7, 7)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 919,146\n",
      "Trainable params: 919,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def base_model4_adam(lr=0.0005,decay=0.0):\n",
    "    input_layer =Input(shape=(1,28,28))\n",
    "    conv_layer1 = Conv2D(32,(5,5),padding = 'same',activation='relu')(input_layer)\n",
    "    conv_layer2 = Conv2D(32,(5,5),padding = 'same',activation='relu')(conv_layer1)\n",
    "    max_pool1 = MaxPooling2D(pool_size=(2,2))(conv_layer2)\n",
    "    main1 = Dropout(0.25)(max_pool1)\n",
    "    conv_layer3 = Conv2D(64,(3,3),padding='same',activation='relu')(main1)\n",
    "    conv_layer4 = Conv2D(64,(3,3),padding='same',activation='relu')(conv_layer3)\n",
    "    max_pool2 = MaxPooling2D(pool_size=(2,2),strides=2)(conv_layer4)\n",
    "    main2 = Dropout(0.2)(max_pool2)\n",
    "    main2 = Flatten()(main2)\n",
    "    main2 = Dense(256,activation='relu')(main2)\n",
    "    main2 = Dense(128,activation='relu')(main2)\n",
    "    output = Dense(10,activation='softmax')(main2)\n",
    "    model = Model(input_layer,output)\n",
    "    #optimizer = Adam(lr=lr,decay=decay)\n",
    "    optimizer = Adam(lr=0.001,beta_1=0.9,beta_2=0.9,epsilon=1e-08,decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "model = base_model4()\n",
    "model.summary()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(zoom_range = 0.05,\n",
    "                            height_shift_range = 0.05,\n",
    "                            width_shift_range = 0.05,\n",
    "                            rotation_range = 3)\n",
    "BATCH_SIZE = 200\n",
    "epochs = 5\n",
    "# Calculate learning rate decay.\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(X_train) / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.002, 0.0003\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "cnn_model = base_model4(lr=lr_init,decay=0)\n",
    "cnn_model.fit_generator(\n",
    "        datagen.flow(X_train, y_train, batch_size=256),steps_per_epoch=1000, epochs=epochs,\n",
    "        validation_data=(X_test, y_test), verbose=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
